+++
draft = false
thumbnail = "/img/CloudUplink.png"
date = "2017-07-04"
title = "Coping with x2,000 data volumes growth"
tags = ["infrastructure","azure","lambda"]
categories = ["DataOps"]
+++

Experience my pain as I try to build an Azure Data Platform that scales.

## Abstract
I worked in a startup and our volumes started small, really small. I was the data scientist but I needed to actually build a data platform first. By the end of 6 months, daily volumes were 2,000 times the size. This talk takes you through my 6 months of learning how to build a high-scale data platform whilst requirements, scale, and technology were all changing. We'll look at the various bits of Azure I used, how they started off or became wrong for my situation, how I designed the system to cope with the constant swapping and changing of technologies, and then we'll look at the system I ended up with that could cope with the scale and at then some.

## Slides
View the presentation [full screen](https://1drv.ms/p/s!AiZm2P6YHtSfkCHsaudeN1AvXP-4) or view it below. Hit the Space bar to navigate through the slides.

<iframe src='https://onedrive.live.com/embed?cid=9FD41E98FED86626&resid=9FD41E98FED86626%212081&authkey=AFK_nMR7G2JELQA&em=2&wdAr=1.7777777777777777' width='1186px' height='691px' frameborder='0'>This is an embedded <a target='_blank' href='https://office.com'>Microsoft Office</a> presentation, powered by <a target='_blank' href='https://office.com/webapps'>Office Online</a>.</iframe>


## Presentation history
- July 4th, 2017 - [Devteach](http://www.devteach.com)
